from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from dotenv import load_dotenv
import os
import logging
import socket

# IelÄdÄ“ .env mainÄ«gos
load_dotenv()

# InicializÄ“ FastAPI
app = FastAPI()

# AtÄ¼aut visus CORS pieprasÄ«jumus (frontenda testÄ“Å¡anai)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logging iestatÄ«jumi
logging.basicConfig(level=logging.INFO)

# ğŸ” Debug: pÄrbaudi, vai API_KEY vispÄr tiek saÅ†emts
api_key = os.getenv("OPENAI_API_KEY")
print("ğŸ” API key (sÄkums):", api_key[:10] if api_key else "None")

client = OpenAI()

@app.get("/")
def root():
    return {"message": "DailySpark backend is running."}

@app.post("/generate")
async def generate_text(request: Request):
    logging.info("ğŸš€ API /generate saÅ†emts!")

    try:
        body = await request.json()
        prompt = body.get("prompt")

        if not prompt:
            return {"error": "Prompt is required."}

        chat_completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        result = chat_completion.choices[0].message.content.strip()
        return {"result": result}

    except Exception as e:
        logging.error(f"âš ï¸ KÄ¼Å«da Ä£enerÄ“Å¡anas laikÄ: {e}")
        return {"error": str(e)}

# âœ… TÄ«kla savienojuma pÄrbaude ar OpenAI API
@app.get("/network-test")
def network_test():
    try:
        host = "api.openai.com"
        port = 443
        ip = socket.gethostbyname(host)
        s = socket.create_connection((ip, port), timeout=5)
        s.close()
        return {"status": "SUCCESS", "ip": ip}
    except Exception as e:
        return {"status": "FAIL", "error": str(e)}
